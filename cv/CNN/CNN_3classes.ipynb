{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4NW5_yJjvTq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# !pip install torchvision\n",
        "import torchvision\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. 设置参数\n",
        "source_folder = \"/kaggle/input/3classes-pneumonia-x-ray-classification/pneumonia-kaggle/train/PNEUMONIA\"  # 包含所有图像的文件夹\n",
        "bacteria_folder = \"/kaggle/working/train/bacteria\"  # 细菌图像的目标文件夹\n",
        "virus_folder = \"/kaggle/working/train/virus\"  # 病毒图像的目标文件夹\n",
        "\n",
        "# 2. 创建目标文件夹\n",
        "os.makedirs(bacteria_folder, exist_ok=True)\n",
        "os.makedirs(virus_folder, exist_ok=True)\n",
        "\n",
        "# 3. 遍历源文件夹中的所有文件\n",
        "for filename in os.listdir(source_folder):\n",
        "    source_path = os.path.join(source_folder, filename)\n",
        "\n",
        "    # 确保是文件而不是文件夹\n",
        "    if os.path.isfile(source_path):\n",
        "        # 根据文件名判断类别 (这里需要根据你的文件名规则进行修改)\n",
        "        if \"bacteria\" in filename.lower():  # 假设细菌图像文件名包含 \"bacteria\"\n",
        "            destination_path = os.path.join(bacteria_folder, filename)\n",
        "            shutil.copy(source_path, destination_path)  # 复制文件\n",
        "            #print(f\"Copied {filename} to bacteria folder\")\n",
        "        elif \"virus\" in filename.lower():  # 假设病毒图像文件名包含 \"virus\"\n",
        "            destination_path = os.path.join(virus_folder, filename)\n",
        "            shutil.copy(source_path, destination_path)  # 复制文件\n",
        "            #print(f\"Copied {filename} to virus folder\")\n",
        "print(\"Classification complete.\")"
      ],
      "metadata": {
        "id": "5hfucrDdj4gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. 设置参数\n",
        "source_folder = \"/kaggle/input/3classes-pneumonia-x-ray-classification/pneumonia-kaggle/train/NORMAL\"  # 源文件夹\n",
        "destination_folder = \"/kaggle/working/train/normal\"  # 目标文件夹\n",
        "\n",
        "# 2. 创建目标文件夹\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# 3. 复制文件\n",
        "for filename in os.listdir(source_folder):\n",
        "    source_path = os.path.join(source_folder, filename)\n",
        "    destination_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "    # 确保是文件\n",
        "    if os.path.isfile(source_path):\n",
        "        shutil.copy(source_path, destination_path)\n",
        "        #print(f\"Copied {filename} to {destination_folder}\")\n",
        "\n",
        "print(\"Copy complete.\")"
      ],
      "metadata": {
        "id": "N8LUfjuPj6d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'validation':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    'train':\n",
        "    datasets.ImageFolder('/kaggle/working/train', data_transforms['train'])\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    'train':\n",
        "    torch.utils.data.DataLoader(image_datasets['train'],\n",
        "                                batch_size=784,\n",
        "                                shuffle=True,\n",
        "                                num_workers=0)\n",
        "}"
      ],
      "metadata": {
        "id": "SD3EoA5Oj8A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "   def __init__(self, in_channels, num_classes):\n",
        "\n",
        "       super(CNN, self).__init__()\n",
        "\n",
        "       # 1st convolutional layer\n",
        "       self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, padding=1)\n",
        "       # Max pooling layer\n",
        "       self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "       # 2nd convolutional layer\n",
        "       self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
        "       # Fully connected layer\n",
        "       self.fc1 = nn.Linear(16 * 56 * 56, 3)\n",
        "\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = F.relu(self.conv1(x))\n",
        "       x = self.pool(x)\n",
        "       x = F.relu(self.conv2(x))\n",
        "       x = self.pool(x)\n",
        "       x = x.reshape(x.shape[0], -1)\n",
        "       x = self.fc1(x)\n",
        "       return x"
      ],
      "metadata": {
        "id": "iUb-9b9qkBuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CNN(in_channels=3, num_classes=3).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "uO0k_YJnkDp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        " # Iterate over training batches\n",
        "   print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "\n",
        "   for batch_index, (data, targets) in enumerate(tqdm(dataloaders['train'])):\n",
        "       data = data.to(device)\n",
        "       targets = targets.to(device)\n",
        "       scores = model(data)\n",
        "       loss = criterion(scores, targets)\n",
        "       optimizer.zero_grad()\n",
        "       loss.backward()\n",
        "       optimizer.step()"
      ],
      "metadata": {
        "id": "Ta0Iq6CUkFu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from PIL import Image\n",
        "\n",
        "model.eval()\n",
        "pred = []\n",
        "filenames = []\n",
        "test_folder = \"/kaggle/input/3classes-pneumonia-x-ray-classification/pneumonia-kaggle/test\"\n",
        "\n",
        "for filename in tqdm(os.listdir(test_folder)):\n",
        "   if filename.endswith(\".jpeg\") or filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
        "        base_filename, ext = os.path.splitext(filename)\n",
        "        filenames.append(base_filename)\n",
        "        img_path = os.path.join(test_folder, filename)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "        except (FileNotFoundError, OSError) as e:\n",
        "            print(f\"Error loading image {filename}: {e}\")\n",
        "            pred.append(-1)\n",
        "            continue\n",
        "\n",
        "        img = data_transforms['validation'](img).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(img)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            predicted_class = predicted.item()\n",
        "            pred.append(predicted_class)"
      ],
      "metadata": {
        "id": "LhU7Mk4mkJdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({'Id': filenames, 'Category': pred})\n",
        "results = results.sort_values(by='Id')\n",
        "results"
      ],
      "metadata": {
        "id": "PIgwVbD-kK4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.to_csv('predictions.csv', index=False)\n",
        "print(\"Prediction complete.\")"
      ],
      "metadata": {
        "id": "TleYUXAFkN5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}